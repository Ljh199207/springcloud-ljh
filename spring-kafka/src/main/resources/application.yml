spring:
  kafka:
    bootstrap-servers: 192.168.27.129:9092,192.168.27.129:9093,192.168.27.129:9094   # 集群
    producer:
      retries: 1    # 重试次数
      acks: 1       # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      batch-size: 16384  # 批量大小
      properties:
        linger:
          ms: 0    # 提交延时
      buffer-memory: 33554432  # 生产端缓冲区大小
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      partitioner:
        class: com.example.springkafka.springkafka.config.CustomizePartitioner
      ###########【初始化消费者配置】###########
    consumer:
      enable-auto-commit: true   # 是否自动提交offset
      auto-commit-interval: 1000     # 提交offset延时(接收到消息后多久提交offset)
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      group-id: defaultConsumerGroup
    listener:
      missing-topics-fatal: false
server:
  port: 8083

